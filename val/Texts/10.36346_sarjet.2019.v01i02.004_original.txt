
An Artificial Intelligence Based Approach to Determine the Elongation % and Ultimate Tensile Strength of Friction Stir Welded Dissimilar Marine Grade Aluminium Alloy Joints
Aug-Sep -2019

Akshansh Mishra 
Founder and Project Scientific Officer
Stir Research Technologies
Uttar Pradesh
India

Abhijeet Singh 
Department of Mechanical Engineering
DIT University
Dehradun Uttarakhand India

Design Engineer
Shinewell Automation Private Limited
Chennai Uttarakhand India

Saravanan M 
Anish Dasgupta 
Technical Officer
Stir Research Technologies
Uttar Pradesh India

An Artificial Intelligence Based Approach to Determine the Elongation % and Ultimate Tensile Strength of Friction Stir Welded Dissimilar Marine Grade Aluminium Alloy Joints

Online) South Asian Research Journal of Engineering and Technology Abbreviated Key Title: South Asian Res J Eng Tech |
Aug-Sep -201910.36346/SARJET.2019.v01i02.004Received: 18.09.2019 Accepted: 26.09.2019Original Research Article *Corresponding Author Akshansh Mishra Article HistoryArtificial Neural NetworkQuasi Newton AlgorithmFriction Stir Welding
Neural networks are a new generation of information processing paradigms designed to mimic some of the behaviours of the human brain. These networks have gained tremendous popularity due to their ability to learn, recall and generalize from training data. A number of neural network paradigms have been reported in the last four decades, and in the last decade the neural networks have been refined and widely used by researchers and application engineers. This study focuses on the prediction of the elongation % and Ultimate Tensile Strength (UTS) of the dissimilar Friction Stir Welded joints of aluminium alloys by training the Neural Network on Quasi Newton Algorithm.

INTRODUCTION

Artificial Neural Network (ANN) is a set of processing units which are assembled together in a closely interconnected network. It strikingly offers same features as biological neurons. Neural networks learn from examples. For example, before solving any exercise of mathematical problems, students train their mind from examples available in the particular chapter. After training their minds on the basis of learning procedures to solve problems, they jump on exercise part. Massive parallel problems can be solved by Artificial Neural Networks (ANNs). An artificial neural network (ANN) is a simplified model of the structure of the biological neural network. Interconnected processing units constitute the Artificial Neural Network.

A typical artificial neural network architecture is shown in the Figure 1.


Fig-1: Artificial Neural Network Architecture

Nowadays, in the field welding process,artificial neural network(ANN) modeling has gained increased importance. DUTTA et al. [1] simulated the gas tungsten arc welding process by using conventional regression analysis and neural network tools and concluded that the performance of ANN was better compared with regression analysis. ATES et al. [2] depicted the use of artificial neural network for predicting the welding parameters in gas metal arc welding. OKUYUCU et al [3] presented the possibility of the use of neural networks in order to calculate the mechanical properties of friction stir welded(FSW) aluminium plates with the help of the process parameters such as rotational speed and welding speed. Tnasel et al. [4] used Genetically Optimized Neural Network System in order to estimate the optimal operating condition of the Friction Stir Welding process. He introduced GONNS by using Artificial Neural Network (ANN) and Genetic Algorithm together,. Friction Stir Welding (FSW) process was presented by him in five artificial neural networks (ANN. The results showed that the inputs of the five ANNs were the same (tool rotation and welding feed rate).

In our present study, we carried out Friction Stir Welding process on dissimilar alloys of Aluminium i.e. AA6061 and AA7075 alloys. The elongation % and Ultimate Tensile Strength of the dissimilar joint was predicted by training the Neural Network on Quasi Newton algorithm.


Experimental Procedure

In this study, 6061-T6 and 7075 aluminium alloys of the dimensions 100 mm X 50 mm X 6 mm were used as base metals. Aluminium alloy plates were machined to required dimensions for butt welding. For Friction Stir Welding H13 tool steel with chemical composition 0.406% C, 1.096% Si, 0.443% Mn, 4.952% Cr, 1.251% Mo, 0.183% V with given dimensions was used as weld tool. The assessed mechanical properties are tabulated in the Table 1.


Table-1: Assessed Mechanical properties

Microsoft Excel file was created for first 15 datasets in order to train the Neural Network. Neural Designer software is used for importing the Excel file and further training and testing datasets. Tool rotational speed (rpm) and Welding speed (WS) are the inputs and Elongation % and Ultimate Tensile Strength (UTS) are targets in the Neural Network architecture as shown in the Figure 1. 


RESULTS AND DISCUSSIONS


Data Sets

The dataset are imported to the Neural designer software in excel spread sheet format as shown in the Table 2. The data available in the spread sheet are assigned input and output labels in order to train the Artificial Neural Network.


Table-2: Data preview table

The following table depicts the names, units, descriptions and uses of all the variables in the data set. The numbers of inputs, targets and unused variables here are 2, 2, and 0, respectively.


Table-3: Variables Table

The next chart illustrates the variables use. It depicts the numbers of inputs (2), targets (2) and unused variables (0).


Fig-3: Variables bars chart

The following pie chart details the uses of all the instances in the data set. The total number of instances is 15. The number of training instances is 9 (60%), the number of selection instances is 3 (20%), the number of testing instances is 3 (20%), and the number of unused instances is 0 (0%).


Fig-4: Instances pie chart

There are not missing values in the data set Table-4


: Data statistics results

The following figure represents the histogram for the variable Tool Rotational Speed (RPM).


Fig-5: Tool Rotational Speed (RPM) distribution

The following chart shows the histogram for the variable Welding Speed (mm/min). The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies. The minimum frequency is 0%, which corresponds to the bins with centers 14.5, 17.5, 23.5, 26.5, 32.5 and 35.5. The maximum frequency is 26.6667%, which corresponds to the bins with centers 11.5, 20.5 and 29.5.


Fig-6: Welding Speed (mm/min) distribution

The following chart shows the histogram for the variable Elongation (%). The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies. The minimum frequency is 0%, which corresponds to the bins with centers 4.803 and 5.441. The maximum frequency is 20%, which corresponds to the bin with center 5.761.


Fig-7: Elongation (%) distribution

The following chart shows the histogram for the variable UTS (Mpa). The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies. The minimum frequency is 0%, which corresponds to the bins with centers 167.9, 187.7 and 194.3. The maximum frequency is 20%, which corresponds to the bins with centers 141.5 and 200.9.


Fig-8: UTS (Mpa) distribution

Box plots display information about the minimum, maximum, first quartile, second quartile or median and third quartile of every variable in the data set. They consist of two parts: a box and two whiskers. The length of the box represents the interquartile range (IQR), which is the distance between the third quartile and the first quartile. The middle half of the data falls inside the interquartile range. The whisker below the box shows the minimum of the variable while the whisker above the box shows the maximum of the variable. Within the box, it will also be drawn a line which represents the median of the variable. Box plots also provide information about the shape of the data. If most of the data are concentrated between the median and the maximum, the distribution is skewed right, if most of the data are concentrated between the median and the minimum, it is said that the distribution is skewed left and if there is the same number of values at the both sides of the median, the distribution is said to be symmetric. The following chart shows the box plot for the variable Tool Rotational Speed (RPM). The minimum of the variable is 400, the first quartile is 400, the second quartile or median is 600, the third quartile is 800 and the maximum is 1000.


Fig-9: Tool Rotational Speed (RPM) box plot

The following chart shows the box plot for the variable Welding Speed (mm/min). The minimum of the variable is 10, the first quartile is 10, the second quartile or median is 20, the third quartile is 30 and the maximum is 40.


Fig-10: Welding Speed (mm/min) box plot

The following chart shows the box plot for the variable Elongation (%). The minimum of the variable is 2.73, the first quartile is 3.27, the second quartile or median is 3.85, the third quartile is 5.13 and the maximum is 5.92.


Fig-11: Elongation % box plot

The following chart shows the box plot for the variable UTS (MPa). The minimum of the variable is 138.16, the first quartile is 145.51, the second quartile or median is 161.14, the third quartile is 184.1 and the maximum is 204.25.


Fig-12: UTS (MPa) box plot

The following figure depicts the histogram for the target variable Elongation (%).


Fig-13: Elongation (%) histogram

The following figure depicts the histogram for the target variable UTS (Mpa).


Fig-14: UTS (MPa) histogram

Scatter plot task plots graphs of all targets versus all input variables. That charts might help to see the dependencies of the targets with the inputs.The following chart shows the scatter plot for the input Tool Rotational Speed (RPM) and the target Elongation (%).


Fig-15: Elongation (%) scatter chart vs Tool Rotational Speed (RPM)

The following chart shows the scatter plot for the input Tool Rotational Speed (RPM) and the target UTS (MPa).


Fig-16: UTS (MPa) scatter chart vs Tool Rotational Speed (RPM)

The following chart shows the scatter plot for the input Welding Speed (mm/min) and the target Elongation (%).


Fig-17: Elongation (%) scatters chart vs Welding Speed (mm/min)

The following chart shows the scatter plot for the input Welding Speed (mm/min) and the target UTS (MPa).


Fig-18: UTS (MPa) scatter chart vs Welding Speed (mm/min)

The following table shows the absolute value of the correlations between all input variables. The minimal correlation is 0.0918292 between the variables Tool Rotational Speed (RPM) and Welding Speed (mm/min). The maximal correlation is 0.0918292 between the variables Tool Rotational Speed (RPM) and Welding Speed (mm/min).


Table-5: Correlation matrix

The absolute value of the linear correlations between all input and target variables is shown in the Table 6. The maximum correlation (0.986308) is yield between the input variable Tool Rotational Speed (RPM) and the target variable UTS (MPa).


Table-6: Elongation (%) linear correlations

The next chart illustrates the dependency of the target Elongation (%) with all the input variables.


Fig-19: Elongation (%) bars chart

The absolute value of the linear correlations between all input and target variables is shown in the Table 7. The maximum correlation (0.986308) is yield between the input variable Tool Rotational Speed (RPM) and the target variable UTS (Mpa).


Table-7: UTS (MPa) linear correlations

The next chart illustrates the dependency of the target UTS (MPa) with all the input variables.


Fig-20: UTS (MPa) bars chart

Constant variables are those columns in the data matrix having always the same value. They do not provide any information to the model but increase its complexity. Constant variables should neither be used as inputs nor as targets, except when the model will need to include them in the future. There are not constant variables in the data set. Repeated instances are those rows in the data matrix having the same values as other rows. They provide redundant information to the model and should not be used for training, selection or testing. There are no repeated instances in the data set. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. The data has not outliers. This task trains a neural network using all the instances, then set as unused the instances that have an error above a given value. Note that the instances are arranged in rows of 10. The total number of instances is 15. The numbers of training, selection, testing and unused instances are 10, 2, 2 and 1, respectively.


Table-8: Instances table

The following pie chart details the uses of all the instances in the data set. There are 10 instances for training (66.7%), 2 instances for selection (13.3%), 2 instances for testing (13.3%) and 1 unused instance (6.67%).


Fig-21: Instances Pie chart

Principal components analysis allows to identify underlying patterns in a data set so it can be expressed in terms of other data set of lower dimension without much loss of information. The resulting data set should be able to explain most of the variance of the original data set by making a variable reduction. The final variables will be named principal components. Since this process is not reversible, it will be only applied to the input variables.

The next chart shows the cumulative explained variance for the principal components. The x-axis represents each of the principal components and the y-axis depicts the cumulative explained variance. As it can be seen, the total explained variance for all the principal components is 100% but if the number of chosen principal components decreases also makes it the total explained variance.


Fig-22: Explained variance chart

Minimum-Maximum is the scaling method for this layer. The values which are used for scaling the inputs, which include the minimum, maximum, mean and standard deviation is shown in the Table 9.


Table-9: Scaling layer

Artificial Neural Network has 2 layers. The following table depicts the size of each layer and its corresponding activation function. The architecture of this neural network can be written as 2:3:2.


Table-10: Number of layers and Activation function

The following table shows the statistics of the parameters of the neural network. The total number of parameters is 17.


Table-11: Neural Network parameters

The size of the unscaling layer is 2, the number of outputs. The unscaling method for this layer is the minimum and maximum. The following table shows the values which are used for scaling the inputs, which include the minimum, maximum, mean and standard deviation.


Table-12: Unscaling layer

Neural Network used in our work is shown in the Figure 23. Neural Network architecture has a scaling layer, a neural network and an un-scaling layer. Scaling neurons represents the yellow circle, the green circles the principal components, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 2, the number of principal components is 2, and the number of outputs is 2. The complexity, represented by the numbers of hidden neurons, is 3.


Fig-23: Neural Network Architecture

The quasi-Newton method is used here as training algorithm. It is based on Newton's method, but does not require calculation of second derivatives. Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. The following figure depicts the losses in each iteration. The initial value of the training loss is 1.09861, and the final value after 87 iterations is 0.109506. The initial value of the selection loss is 67.587, and the final value after 87 iterations is 154.445.


Fig-24: Quasi-Newton method losses history

The next table shows the training results by the quasi-Newton method. They include some final states from the neural network, the loss functional and the training algorithm. 


MODEL SELECTION

Model selection is applied to find a neural network with a topology that optimizes the loss on new data. There are two different types of algorithms for model selection: Order selection algorithms and input selection algorithms. Order selection algorithms are used to find the optimal number of hidden neurons in the network. Inputs selection algorithms are responsible for finding the optimal subset of input variables.The inputs selection algorithm chosen for this application is growing inputs. With this method, the inputs are added progressively based on their correlations with the targets.The order selection algorithm chosen for this application is incremental order. This method starts with the minimum order and adds a given number of perceptrons in each iteration.

Input importance task calculates the selection loss when removing one input at a time. This shows which input have more influence in the outputs.The next table shows the importance of each input. If the importance takes a value greater than 1 for an input, it means that the selection error without that input is greater than with it. In the case that the importance is lower than 1, the selection error is lower without using that input. Finally, if the importance is 1, there is no difference between using the current input and not using it. The most important variable is Welding Speed (mm/min), that gets a contribution of 123.3% to the outputs.


Table-14: Inputs importance results

The next chart illustrates the contribution of each input.


Fig-25: Contribution bars chart

The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. Incremental order is used here as order selection algorithm in the model selection. The next chart shows the loss history for the different subsets during the incremental order selection process. The blue line represents the training loss and the red line symbolizes the selection loss.


Fig-26: Incremental order losses plot

The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the loss functional and the order selection algorithm.


Table-15: Incremental order results

A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the green circles the principal components, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 2, the number of principal components is 2, and the number of outputs is 2. The complexity, represented by the numbers of hidden neurons, is 1.


Fig-27: Final architecture

The next plot lists the linear regression parameters for the scaled output Elongation (%).


Table-16: Elongation (%) linear regression parameters

The next figure depicts the linear regression for the scaled output Elongation %.


Fig-28: Elongation (%) linear regression chart

The next plot lists the linear regression parameters for the scaled output UTS (Mpa).


Table 17: UTS (MPa) linear regression parameters

The next figure depicts the linear regression for the scaled output UTS (Mpa).


Fig-29: UTS (MPa) linear regression chart

Testing errors task measures all the losses of the model. it takes in account every used instance and evaluate the model for each use.The next table shows all the errors of the data for each use of them.


Table-18: Errors table

A neural network produces a set of outputs for each set of inputs applied. The outputs depend, in turn, on the values of the parameters. The next table shows the input values and their corresponding output values. The input variables are Tool Rotational Speed (RPM) and Welding Speed (mm/min); and the output variables are Elongation (%) and UTS (MPa).


Table-19: Inputs-outputs table

It is very useful to see the how the outputs vary as a function of a single input, when all the others are fixed. This can be seen as the cut of the neural network model along some input direction and through some reference point. The next plot shows the output Elongation (%) as a function of the input Tool Rotational Speed (RPM). The x and y axes are defined by the range of the variables Tool Rotational Speed (RPM) and Elongation (%), respectively.


Fig-30: Elongation (%) against Tool Rotational Speed (RPM) directional line chart

The next plot shows the output UTS (MPa) as a function of the input Tool Rotational Speed (RPM). The x and y axes are defined by the range of the variables Tool Rotational Speed (RPM) and UTS (MPa), respectively.


Fig-31: UTS (MPa) against Tool Rotational Speed (RPM) directional line chart

The next plot shows the output Elongation (%) as a function of the input Welding Speed (mm/min). The x and y axes are defined by the range of the variables Welding Speed (mm/min) and Elongation (%), respectively. 

Fig- 2 :
2Neural Designer software workbench

Fig- 32 :
32Elongation (%) against Welding Speed (mm/min) directional line chart

Table - 13
-: Quasi-Newton method results
Â© South Asian Research Publication, Bangladesh Journal Homepage: www.sarpublication.com/sarjet
The next plot shows the output UTS (Mpa) as a function of the input Welding Speed (mm/min). The x and y axes are defined by the range of the variables Welding Speed (mm/min) and UTS (Mpa), respectively. Note that some directional outputs fall outside the range of UTS (Mpa), and therefore they are not plotted.Fig-33: UTS (MPa) against Welding Speed (mm/min) directional line chart CONCLUSIONIf we observe the results obtained from the experimental data and predicted value obtained by Artificial Neural Network architecture they are closer to each other.Accuracy of 98.47% and 80.73% was achieved for predicting the values of the elongation % and Ultimate Tensile Strength (UTS) respectively.
Modeling of TIG welding process using conventional regression analysis and neural networkbased approaches. P Dutta, D K Pratihar, Journal of Materials Processing Technology. 1841-3Dutta, P., & Pratihar, D. K. (2007). Modeling of TIG welding process using conventional regression analysis and neural network- based approaches. Journal of Materials Processing Technology, 184(1-3), 56-68.

Prediction of gas metal arc welding parameters based on artificial neural networks. H Ates, Materials & design. 287Ates, H. (2007). Prediction of gas metal arc welding parameters based on artificial neural networks. Materials & design, 28(7), 2015-2023.

Artificial neural network application to the friction stir welding of aluminum plates. H Okuyucu, A Kurt, E Arcaklioglu, Materials & design. 281Okuyucu, H., Kurt, A., & Arcaklioglu, E. (2007). Artificial neural network application to the friction stir welding of aluminum plates. Materials & design, 28(1), 78-84.

Optimizations of friction stir welding of aluminum alloy by using genetically optimized neural network. I N Tansel, M Demetgul, H Okuyucu, A Yapici, The International Journal of Advanced Manufacturing Technology. 481-4Tansel, I. N., Demetgul, M., Okuyucu, H., & Yapici, A. (2010). Optimizations of friction stir welding of aluminum alloy by using genetically optimized neural network. The International Journal of Advanced Manufacturing Technology, 48(1-4), 95-101.
