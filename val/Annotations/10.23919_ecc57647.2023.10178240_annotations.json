{
    "title": [
        {
            "start": 1,
            "end": 72,
            "text": "Distributed Stochastic Bandit Learning with Delayed Context Observation"
        },
        {
            "start": 117,
            "end": 188,
            "text": "Distributed Stochastic Bandit Learning with Delayed Context Observation"
        }
    ],
    "abstract": [
        {
            "start": 292,
            "end": 1353,
            "text": "We consider the problem where M agents collaboratively interact with an instance of a stochastic K-armed contextual bandit, where K M. The goal of the agents is to simultaneously minimize the cumulative regret over all the agents over a time horizon T . We consider a setting where the exact context is observed after a delay and at the time of choosing the action the agents are unaware of the context and only a distribution on the set of contexts is available. Such a situation arises in different applications where at the time of the decision the context needs to be predicted (e.g., weather forecasting or stock market prediction), and the context can be estimated once the reward is obtained. We propose an Upper Confidence Bound (UCB)-based distributed algorithm and prove that our algorithm achieves regret and communications bounds of O(d âˆš MT log 2 T ) and O(M 1.5 d 3 ), respectively, for linearly parametrized reward functions. We validated the performance of our algorithm via numerical simulations on synthetic data and real-world Movielens data."
        }
    ],
    "author": [
        {
            "start": 75,
            "end": 85,
            "text": "Jiabin Lin"
        },
        {
            "start": 87,
            "end": 115,
            "text": "Member, IEEEShana Moothedath"
        }
    ]
}